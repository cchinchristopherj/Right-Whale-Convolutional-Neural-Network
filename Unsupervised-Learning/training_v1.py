import whale_cnn
import whale_cnn_unsup
import numpy 
from skimage.transform import resize
from sklearn.metrics import roc_auc_score
from sklearn.cluster import MiniBatchKMeans
from sklearn.feature_extraction import image
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler, normalize
from sklearn.metrics.pairwise import pairwise_distances
from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping
from keras import layers
from keras.layers import Input, Lambda, Dense, Reshape, Dropout, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Concatenate 
from keras.models import load_model, Model
from keras.optimizers import Adam
import tensorflow as tf
import keras
import keras.backend as K
K.set_image_data_format('channels_last')

def create_model(num_groups,group_size,kernel_size,input_shape,connections_1f,connections_2f,connections_1m,connections_2m):
    ''' create_model Method
            CNN Model for Right Whale Upcall Recognition with filters learned through K-Means
            and energy-correlated receptive fields
            
            Args:
                num_groups: int number of groups to split the filters of the first and second
                            layers into 
                group_size: int size of the groups created in the first and second layers
                kernel_size: int size of the filters in the Conv2D layers (same kernel size
                             for all three layers)
                input_shape: (Number of Samples, Height, Width, Number of Filters)
                connections_1f: 2-D matrix of connections created by "learn_connections_unsup"
                                comprised of "num_groups" rows and "group_size" columns, for
                                the first layer
                connections_2f: 2-D matrix of connections created by "learn_connections_unsup"
                                for the second layer
                connections_1m: Mask in the shape of a representative feature map, to be
                                broadcasted across all feature maps in the first layer
                connections_2m: Mask in the shape of a representative feature map, to be 
                                broadcasted across all feature maps in the second layer
            Returns: 
                Compiled Keras CNN Model
                
    '''
    # There are three layers: Layer 0 is the convolution of the raw input layer with the
    # first set of learned filters (each filter is of depth 1 because the raw input layer 
    # is of depth 1). Layer 1 corresponds to the second set of learned filters (each filter is
    # of depth "group_size" and the learned filters are applied to smaller groups of the
    # entire set, each group being of depth "group_size"). Layer 2 corresponds to the third set 
    # of learned filters (each filter is of depth "group_size" and the learned filters are also 
    # applied to smaller groups of the entire set, each group being of depth "group_size").
    X_input = Input(shape=input_shape,name='input')
    # Dropout on the visible layer (1 in 5 probability of dropout) 
    X = Dropout(0.2,name='dropout0')(X_input)
    # BatchNorm on axis=3 (on the axis corresponding to the number of filters)
    X = BatchNormalization(axis=3,name='bn0')(X)
    # Convolution of Filters with Input. Since the filters are determined through unsupervised
    # learning, they are not updated through backpropagation (i.e. trainable=False)
    X = Conv2D(filters=num_groups*group_size,kernel_size=kernel_size,use_bias=False,activation='relu',name='conv0',trainable=False)(X)
    # Maxpooling for translation invariance and to halve height and width dimensions 
    X_maps1 = MaxPooling2D(name='maxpool0')(X)
    # connections_1m is a mask of 0s and 1s to multiply X_maps1 by. The mask was generated by
    # using a pairwise similarity metric (energy-correlation) to determine which parts of 
    # X_maps1 are most strongly correlated. (Parts that are not strongly correlated are 
    # replaced by zeros to aid training more discriminative filters via K-Means).
    X_maps1_masked = Lambda(lambda X: K.tf.multiply(X,connections_1m),name='masked1')(X_maps1)
    # The filters learned via K-Means for the next layer are trained on groups of feature maps
    # instead of the entire set. Specifically, the set of feature maps from X_maps1_masked
    # are broken up into "num_groups" groups of "group_size" filters, with the groups
    # determined via energy correlation. (The reduced dimensionality improves the performance 
    # of K-Means). These smaller groups of feature maps are then fed to K-Means to generate
    # new filters. Note, however, that it is not possible to apply the learned filters of 
    # reduced dimensionality immediately to the output of X_maps1_masked of full dimensionality.
    # In order to account for this discrepancy, the output of X_maps1_masked is split
    # into the same groups used for K-Means, and all the learned filters applied to each of
    # these smaller groups. For example, suppose X_maps1_masked originally has 64 feature maps, 
    # and these are split into 16 groups of 4 feature maps. After these groups are fed into 
    # K-Means and, say, 128 filters are generated, X_maps1_masked is split into the same 
    # 16 groups of 4 feature maps. Then, the 128 filters are applied to each of these 16 
    # groups (since each group is the same size as the groups originally fed to K-Means). The
    # results are then concatenated along the axis corresponding to the number of filters
    # (the last axis) to represent the output of the convolution. 
    # The dictionaries below are used to implement this grouping mechanism. Note that the 
    # connections_1f array contains all the groups of feature maps determined via 
    # energy-correlation. This array is used to slice the original set of feature maps into
    # the desired groups. 
    layers_1 = dict()
    # connections_1f is composed of "num_groups" rows and "group_size" columns
    # layers_1_lambda, layers_1_reshape, and layers_1_maxpool are dictionaries of 
    # sub-dictionaries, where each sub-dictionary corresponds to one of the "num_groups" groups 
    # in connections_1f
    layers_1_lambda = dict()
    layers_1_reshape = dict()
    layers_1_maxpool = dict()
    for ii in range(num_groups):
        # Instantiate the sub-dictionaries for each main dictionary, for the current group
        # under consideration
        layers_1[ii] = dict()
        layers_1_lambda[ii] = dict()
        layers_1_reshape[ii] = dict()
        layers_1_maxpool[ii] = dict()
        for jj in range(group_size):
            # For the current group under consideration (represented by ii) and the current
            # member of the group under consideration (represented by jj), use Keras'
            # Lambda layer to select that one member of the group (that one feature map) 
            # from the entire main group. Then use Keras' Reshape layer to reshape the 
            # dimensions of the output of the Lambda layer to:
            # (Number of samples, height, width, 1)
            layers_1_lambda[ii]['X_lambda_'+str(ii)+'_'+str(jj)] = Lambda(lambda X: X[:,:,:,connections_1f[ii,jj]],name='lambda1_'+str(ii)+'_'+str(jj))(X_maps1_masked)
            layers_1_reshape[ii]['X_reshape_'+str(ii)+'_'+str(jj)] = Reshape((*K.int_shape(layers_1_lambda[ii]['X_lambda_'+str(ii)+'_'+str(jj)])[1:3],1),name='reshape1_'+str(ii)+'_'+str(jj))(layers_1_lambda[ii]['X_lambda_'+str(ii)+'_'+str(jj)])
        # After the for loop above, layers_1_reshape[ii] contains all the individual feature
        # maps comprising the current group under consideration. Concatenate all of them into
        # one group of "group_size" feature maps using keras.layers.concatenate
        layers_1_concat = [layer for layer in layers_1_reshape[ii].values()]
        layers_1[ii]['X_concat_'+str(ii)] = keras.layers.concatenate(layers_1_concat,name='concat1_'+str(ii))
        # Apply BatchNorm along axis=3 as before
        layers_1[ii]['X_batchnorm_'+str(ii)] = BatchNormalization(axis=3,name='bn1_'+str(ii))(layers_1[ii]['X_concat_'+str(ii)])
        # Apply all the filters learned via K-Means to the current group of feature maps
        # under consideration. (Note that samples from all the groups were fed into K-Means to 
        # learn these filters (num_groups*group_size/8 filters were learned). These
        # num_groups*group_size/8 filters were applied to the current group under consideration.
        layers_1[ii]['X_conv2d_'+str(ii)] = Conv2D(filters=group_size,kernel_size=kernel_size,use_bias=False,activation='relu',name='conv1_'+str(ii),trainable=False)(layers_1[ii]['X_batchnorm_'+str(ii)])
        # Maxpooling was applied for translation invariance and to halve the width and height
        # dimensions
        layers_1_maxpool[ii]['X_maxpool2d_'+str(ii)] = MaxPooling2D(pool_size=(2,2),name='maxpool1_'+str(ii))(layers_1[ii]['X_conv2d_'+str(ii)])
    # Concatenate the results for all the groups into one set. This is done because 
    # connections_2f separates this entire set into energy-correlated groups (presumably 
    # different groups than specified by connections_1f).
    layers_1_final = []
    for ii in range(num_groups):
        # The sub-dictionaries in the layers_1_maxpool main dictionary contain all the
        # results to be concatenated
        layers_1_final.extend([layer for layer in layers_1_maxpool[ii].values()])
    X_maps2 = keras.layers.concatenate(layers_1_final,name='final1')
    # Repeat all the steps above for the third layer. Multiply X_maps2 by the mask represented
    # by connections_2m
    X_maps2_masked = Lambda(lambda X: K.tf.multiply(X,connections_2m),name='masked2')(X_maps2)
    # Generate the main dictionaries 
    layers_2 = dict()
    layers_2_lambda = dict()
    layers_2_reshape = dict()
    layers_2_maxpool = dict()
    for ii in range(num_groups):
        # Generate the sub-dictionaries
        layers_2[ii] = dict()
        layers_2_lambda[ii] = dict()
        layers_2_reshape[ii] = dict()
        layers_2_maxpool[ii] = dict()
        for jj in range(group_size):
            # For each group, compile each feature map member individually using the Lambda
            # and Reshape layers
            layers_2_lambda[ii]['X_lambda_'+str(ii)+'_'+str(jj)] = Lambda(lambda X: X[:,:,:,connections_2f[ii,jj]],name='lambda2_'+str(ii)+'_'+str(jj))(X_maps2_masked)
            layers_2_reshape[ii]['X_reshape_'+str(ii)+'_'+str(jj)] = Reshape((*K.int_shape(layers_2_lambda[ii]['X_lambda_'+str(ii)+'_'+str(jj)])[1:3],1),name='reshape2_'+str(ii)+'_'+str(jj))(layers_2_lambda[ii]['X_lambda_'+str(ii)+'_'+str(jj)])
        # Concatenate the feature maps for the group under consideration into one set
        layers_2_concat = [layer for layer in layers_2_reshape[ii].values()]
        layers_2[ii]['X_concat_'+str(ii)] = keras.layers.concatenate(layers_2_concat,name='concat2_'+str(ii))
        layers_2[ii]['X_batchnorm_'+str(ii)] = BatchNormalization(axis=3,name='bn2_'+str(ii))(layers_1[ii]['X_concat_'+str(ii)])
        # Apply the learned filters (num_groups*group_size/4 of them) to each of these 
        # smaller feature map groups
        layers_2[ii]['X_conv2d_'+str(ii)] = Conv2D(filters=group_size,kernel_size=kernel_size,use_bias=False,activation='relu',name='conv2_'+str(ii),trainable=False)(layers_2[ii]['X_batchnorm_'+str(ii)])
        layers_2_maxpool[ii]['X_maxpool2d_'+str(ii)] = MaxPooling2D(pool_size=(2,2),name='maxpool2_'+str(ii))(layers_2[ii]['X_conv2d_'+str(ii)])
    # Concatenate the results for all the groups into one set.
    layers_2_final = []
    for ii in range(num_groups):
        layers_2_final.extend([layer for layer in layers_2_maxpool[ii].values()])
    X_maps3 = keras.layers.concatenate(layers_2_final,name='final2')
    # Flatten the output from the first, second, and third layers
    X_maps1_f = Flatten(name='flatten1')(X_maps1)
    X_maps2_f = Flatten(name='flatten2')(X_maps2)
    X_maps3_f = Flatten(name='flatten3')(X_maps3)
    # Concatenate the flattened outputs into one feature vector
    X_maps = keras.layers.concatenate([X_maps1_f,X_maps2_f,X_maps3_f],name='final3')
    # Dropout on the fully connected layer (1 in 2 probability of dropout) 
    X = Dropout(0.5,name='dropout3')(X_maps)
    # Feed the feature vector into the Dense layer for binary classification
    X_output = Dense(1,activation='sigmoid',name='fc1')(X)
    # Use Adam optimizer
    opt = Adam(lr=0.0001,beta_1=0.9,beta_2=0.999,decay=0.01)
    model = Model(inputs=X_input,outputs=X_output)
    model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])
    return model

# Parameters for Training Model:
# Size of Filters (kernel_size x kernel_size) in Keras model for all convolutional layers
kernel_size= 7
# Number of groups of filters 
num_groups_f = 64
# Number of feature maps in each group
group_size_f = 4
# Size of layer 1 output in model after maxpooling
maxpool1_shape = int((X_train.shape[2]-kernel_size+1)/2)
# Size of layer 2 output in model after maxpooling
maxpool2_shape = int((maxpool1_shape-kernel_size+1)/2)
# Number of groups for "learn_connections_unsup" when learning the mask for layer 1
num_groups_m1 = 50
# Number of groups for "learn_connections_unsup" when learning the mask for layer 2
num_groups_m2 = 15
# The size of the group when learning the mask for layer 1
group_size_m1 = maxpool1_shape
# The size of the group when learning the mask for layer 2
group_size_m2 = 5
# Input Shape: (Number of Samples, Height, Width, Number of Filters)
input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3])
# Instantiate arrays for connections matrices as the expected sizes so that the Keras
# model can be instantiated with the proper architecture. These values will be changed
# once the connections are learned, and the model updated with these learned values
connections_1f = numpy.arange(num_groups_f*group_size_f).reshape(num_groups_f,group_size_f)
connections_1f = numpy.asarray(connections_1f,numpy.int32)
connections_2f = numpy.arange(num_groups_f*group_size_f).reshape(num_groups_f,group_size_f)
connections_2f = numpy.asarray(connections_2f,numpy.int32)
connections_1m = numpy.ones((1,maxpool1_shape,maxpool1_shape,1))
connections_2m = numpy.ones((1,maxpool2_shape,maxpool2_shape,1))
# Instantiate the Keras model with the proper architecture
model = create_model(num_groups_f,group_size_f,kernel_size,input_shape,connections_1f,connections_2f,connections_1m,connections_2m)
# "k_train" is the set of samples fed to K-Means to learn filters unsupervised
k_train = X_train.transpose((0,3,1,2))
# The "separate_trainlabels" function shuffles the training set (and training labels), and 
# and yields the indices to replicate the shuffling operation. The function also generates
# "Y_pos" and "Y_neg," arrays containing indices of the samples in the training set belonging
# to the positive and negative class, respectively. ("Y_pos" and "Y_neg" are each set to 
# contain 225 samples). Equal number of samples from each of these arrays are therefore given 
# to K-Means, so that K-Means is able to learn its dictionary of filters based off features 
# from both the positive and negative class. 
Y_pos,Y_neg,indices = separate_trainlabels(Y_train)
# Shuffle k_train, model_train, and model_labels according to the indices specified by 
# "separate_trainlabels"
k_train = k_train[indices]
model_train = X_train[indices]
model_labels = Y_train[indices]
# Feed 50 examples from the positive class and 50 examples from the negative class to 
# K-Means to learn a dictionary of filters. Identify those examples in k_train using the
# indices in the Y_pos and Y_neg arrays 
k_train = numpy.concatenate((k_train[Y_pos[0:50]],k_train[Y_neg[0:50]]),axis=0)
# Use the "MiniBatchKMeansAutoConv" function to learn the dictionary of filters. Extract
# 1/3 of the total number of patches randomly from each sample for training, learn
# num_groups_f*group_size_f filters (centroids), and do not use recursive autoconvolution 
centroids_0 = MiniBatchKMeansAutoConv(k_train,(kernel_size,kernel_size),0.33,num_groups_f*group_size_f,[0])
print('finished learning filters')
# The learned filters (centroids) will be set as the weights of the "conv0" layer.
layer_toset = model.get_layer('conv0')
# Reshape the learned filters so that they are the same shape as expected by the Keras layer
filters = centroids_0.transpose((2,3,1,0))
filters = filters[numpy.newaxis,...]
layer_toset.set_weights(filters)
print('finished setting filters')
# Construct an intermediate model (using model_fp) that generates the output of layer 
# "maxpool0." This is the output that the next set of learned filters will be convolved with.
# Therefore, generate the output for further processing (i.e. learning filter and mask 
# connections)
# For sake of efficiency, continue using only the 225 samples in Y_pos and 225 samples in Y_neg 
# for the processing below (i.e. forward pass only these 450 samples from the training set
# through the Keras model and obtain the output of layer "maxpool0" for only these samples).
fp_train = numpy.concatenate((model_train[Y_pos],model_train[Y_neg]),axis=0)
output_0 = model_fp(model,fp_train,'maxpool0')
# Transpose the output into shape: (Number of samples, number of filters, height, width)
# for "learn_connections_unsup" and "MiniBatchKMeansAutoConv"
output_0 = output_0.transpose((0,3,1,2))
print('finished producing output')
# For sake of efficiency, use only the first 10 and last 10 examples from output_0 for
# learning filter connections via "learn_connections_unsup"
output_0_learnf = numpy.concatenate((output_0[0:10],output_0[-10:]),axis=0)
print('learning connections')
# Use the "learn_connections_unsup" function to find "num_groups_f" groups of feature maps 
# of size "group_size" that are most strongly correlated (using the "energy correlation" 
# pairwise similarity metric). In this case, to calculate the pairwise similaritiy metrics,
# the "samples" are the feature maps (depth dimension) and the "features" are the elements in 
# each feature map (height*width dimension) 
connections_1f = learn_connections_unsup(output_0_learnf,num_groups_f,group_size_f,flag=0)
print('finished learning f connections')
# Use the "learn_connections_unsup" function to find the "num_groups_m1" groups of feature
# map elements of size "group_size_m1" that are most strongly correlated. In this case, to 
# calculate the pairwise similarity metrics, the "samples" are the feature map elements
# (height*width dimension) and the "features" are the different feature maps (depth dimension)
# For sake of efficiency, again use only the first 10 and last 10 samples of output_0 
output_0_learnm = numpy.concatenate((output_0[0:10],output_0[-10:]),axis=0)
mask_1m = learn_connections_unsup(output_0_learnm,num_groups_m1,group_size_m1,flag=1)
print('finished learning m connections')
# Find all the unique feature map elements selected using "learn_connections_unsup
mask_1m = numpy.unique(mask_1m.flatten())
# Create a mask by setting all the selected feature map elements to 1, and the non-selected
# feature map elements to 0. This ensures that the feature map elements not strongly 
# correlated with others are zeroed out during training the Keras model. Note that the mask 
# is set up for the elements in one feature map, and broadcasted to all the other feature
# maps. (Therefore, if the top leftmost element were zeroed out in the mask, it would be 
# zeroed out in every feature map). Also note that learn_connections_unsup generates indices 
# of the correlated feature map elements as if the one feature map to be broadcasted were 
# flattened. Therefore, the indices are set on a flattened version of the feature map
# to be broadcasted, then reshaped into the proper shape.
connections_1m = numpy.zeros((output_0.shape[2]*output_0.shape[3]))
connections_1m[mask_1m] = 1
connections_1m = connections_1m.reshape((output_0.shape[2],output_0.shape[3]))  
connections_1m = connections_1m[numpy.newaxis,numpy.newaxis,:,:]
print('finished making connections_1m')
# The feature maps fed into K-Means to learn the next set of filters are split into groups of 
# reduced dimensionality (to boost performance), with the groups determined by the results
# of connections_1f. Achieve this splitting by repeating output_0 "num_groups_f" times, each
# time using only the filters in one of the "num_groups_f" groups of connections_1f. 
# "output_0_connected" holds all these versions of output_0 with the different sets of 
# filters selected. K-Means will receive samples from each of these different versions of 
# output_0 to learn the next dictionary of filters 
output_0_connected = numpy.zeros((output_0.shape[0]*num_groups_f,group_size_f,output_0.shape[2],output_0.shape[3]))
index = 0
# For sake of efficiency, do not use all the samples in each version of output_0. Only use
# the first and last 10 samples in each version of output_0. "k_train_indices" keeps track
# of what all these indices are, so that the appropriate samples may be selected for feeding
# into K-Means
k_train_indices = []
for ii in range(num_groups_f):
    output_0_connected[index:index+output_0.shape[0],:,:,:] = output_0[:,connections_1f[ii,:],:,:]
    temp1 = numpy.arange(index,index+10)
    k_train_indices.extend(temp1)
    temp2 = numpy.arange((index+output_0.shape[0])-10,(index+output_0.shape[0]))
    k_train_indices.extend(temp2)
    index = index + output_0.shape[0]
print('finished output_0_connected')
k_train = output_0_connected[k_train_indices]
print('learning filters for layer 1')
# Use the "MiniBatchKMeansAutoConv" function to learn the dictionary of filters. Extract
# 1/3 of the total number of patches randomly from each sample for training, learn
# group_size_f filters (centroids), and do not use recursive autoconvolution 
# Since group_size_f filters are learned, all the filters convolved with each of
# the "num_groups_f" groups in the Keras model, and the results concatenated, there will be
# a total of num_groups_f*group_size_f filters in the next layer.
centroids_1 = MiniBatchKMeansAutoConv(k_train,(kernel_size,kernel_size),0.33,group_size_f,[0])
print('finished learning filters')
# Reshape the mask into the shape expected by the Keras model
connections_1m = connections_1m.transpose((0,2,3,1))
# Re-instantiate the model with the newly-set connections_1f and connections_1m 
model = create_model(num_groups_f,group_size_f,kernel_size,input_shape,connections_1f,connections_2f,connections_1m,connections_2m)
print('finished creating model')
# Since the model is re-instantiated, re-set the filters for "conv_0" 
layer_toset = model.get_layer('conv0')
filters = centroids_0.transpose((2,3,1,0))
filters = filters[numpy.newaxis,...]
layer_toset.set_weights(filters)
print('finished setting filters')
# Since the the new set of learned filters is convolved with each of the smaller groups of
# feature maps of reduced dimensionality, each learned filter is the same shape (height, width,
# depth) as each of these smaller groups. Therefore, there is one "conv" layer for each of 
# these smaller groups in the Keras model that will be set to the newly-learned set of filters.
# Set those filters using the for loop below 
for ii in range(num_groups_f):
    layer_toset = model.get_layer('conv1_'+str(ii))
    filters = centroids_1.transpose((2,3,1,0))
    filters = filters[numpy.newaxis,...]
    layer_toset.set_weights(filters)
print('finished setting filters')
# For sake of efficiency, continue using only the 225 samples in Y_pos and 225 samples in Y_neg 
# for the processing below (i.e. forward pass only these 450 samples from the training set
# through the Keras model and obtain the output of layer "final1" for only these samples).
output_1 = model_fp(model,fp_train,'final1')
# Transpose output_1 for "learn_connections_unsup" and "MiniBatchKMeansAutoConv"
output_1 = output_1.transpose((0,3,1,2))
print('finished producing output')
# For sake of efficiency, use only the first 10 and last 10 samples of output_1 for 
# "learn_connections_unsup"
output_1_learnf = numpy.concatenate((output_1[0:10],output_1[-10:]),axis=0)
print('learning connections')
# Learn filter connections
connections_2f = learn_connections_unsup(output_1_learnf,num_groups_f,group_size_f,flag=0)
print('finished learning f connections')
# Learn mask connections
output_1_learnm = numpy.concatenate((output_1[0:10],output_1[-10:]),axis=0)
mask_2m = learn_connections_unsup(output_1_learnm,num_groups_m2,group_size_m2,flag=1)
print('finished learning m connections')
# Apply the mask to the representative feature map (to be broadcasted to all feature maps)
mask_2m = numpy.unique(mask_2m.flatten())
connections_2m = numpy.zeros((output_1.shape[2]*output_1.shape[3]))
connections_2m[mask_2m] = 1
connections_2m = connections_2m.reshape((output_1.shape[2],output_1.shape[3])) 
connections_2m = connections_2m[numpy.newaxis,numpy.newaxis,:,:]
print('finished making connections_2m')
# Repeat output_1 "num_groups_f" times, each time using only the filters in one of the 
# "num_groups_f" groups of connections_2f. "output_1_connected" holds all these versions of 
# output_1 with the different sets of filters selected. 
output_1_connected = numpy.zeros((output_1.shape[0]*num_groups_f,group_size_f,output_1.shape[2],output_1.shape[3]))
index = 0
for ii in range(num_groups_f):
    output_1_connected[index:index+output_1.shape[0],:,:,:] = output_1[:,connections_2f[ii,:],:,:]
    index = index + output_1.shape[0]
print('finished output_1_connected')
k_train = output_1_connected
print('learning filters for layer 2')
# Learn the next set of filters using all samples from output_1_connected. Take one half of
# the maximum number of patches per sample and laern group_size_f filters (centroids).
# Since group_size_f filters are learned, all the filters convolved with each of the 
# "num_groups_f" groups in the Keras model, and the results concatenated, 
# there will be a total of num_groups_f*group_size_f filters in the next layer.
centroids_2 = MiniBatchKMeansAutoConv(k_train,(kernel_size,kernel_size),0.5,group_size_f,[0])
print('finished learning filters')
# Reshape connections_2m into the shape expected by the Keras model
connections_2m = connections_2m.transpose((0,2,3,1))
# Re-instantiate the Keras model with the newly-set connections_2f and connections_2m
model = create_model(num_groups_f,group_size_f,kernel_size,input_shape,connections_1f,connections_2f,connections_1m,connections_2m)
# Since the model is re-instantiated, re-set the filters for "conv_0" 
layer_toset = model.get_layer('conv0')
filters = centroids_0.transpose((2,3,1,0))
filters = filters[numpy.newaxis,...]
layer_toset.set_weights(filters)
print('finished setting filters')
# Since the model is re-instantiated, re-set the filters for convolutional layers in Layer 1
for ii in range(num_groups_f):
    layer_toset = model.get_layer('conv1_'+str(ii))
    filters = centroids_1.transpose((2,3,1,0))
    filters = filters[numpy.newaxis,...]
    layer_toset.set_weights(filters)
print('finished setting filters')
# Set the filters for convolutional layers in Layer 2
for ii in range(num_groups_f):
    layer_toset = model.get_layer('conv2_'+str(ii))
    filters = centroids_2.transpose((2,3,1,0))
    filters = filters[numpy.newaxis,...]
    layer_toset.set_weights(filters)
